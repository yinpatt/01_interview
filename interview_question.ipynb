{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "This notebook includes the answers of Patrick Leung to the HK01 interview question.\n",
    "\n",
    "To make all the code in Q2 & Q3 executable, all the required data are stored on the google sheet below:\n",
    "https://docs.google.com/spreadsheets/d/1LvC5wRR4x2BL-cKPr_8sb4NGdW1TtdNeGj-r_yGJAHo/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 SQL Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SELECT DISTINCT uid\n",
    "FROM piwik_track\n",
    "WHERE event_name = ‘FIRST_INSTALL’\n",
    "AND time = ‘2017-04-01’\n",
    "\n",
    "INTERSECT\n",
    "\n",
    "SELECT DISTINCT uid\n",
    "FROM piwik_track\n",
    "WHERE time >= ‘2017-04-02’\n",
    "AND time <= ‘2017-04-08’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Data Frame Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data, which was copy and pasted from a google sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRybGDvxCZ2dK7UPdKHUv8BG3QkNedvDrDOkrYf664i1uA_mpKh7L3BexFLwMkWytapJCXeQW2gJD7q/pub?gid=0&single=true&output=tsv'\n",
    "df = pd.read_csv(url, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the date & time to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['date']  = df.date.apply(lambda x: x[:4]+'-'+x[5:7]+'-'+x[8:10])\n",
    "df['datetime'] = pd.to_datetime(df.date +' ' +df.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the criteria for the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "condition = (df.datetime>'2017-08-24') & (df.datetime<'2017-08-25') & df.url.apply(lambda x: '.jpg' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[condition,'size'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3a Chinese NLP Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "##### 1) How well does your model perform?\n",
    "Please check 3.1 below. According to a 10 fold cross validation, the model performs close to ~0.99 precision, and it generalize well in unseen data\n",
    "\n",
    "##### 2) How did you choose the parameters of the final model?\n",
    "Please check 3.2. To choose the best parameters of the final model, we can use a grid search which loops through all potential parameters within a chosen range. \n",
    "\n",
    "\n",
    "##### 3) On a high level, please explain your final model’s structure, and how it predicts tags from the article text\n",
    "The methodology of the model is, \n",
    "\n",
    "1) clean and tokenize chinese words into bigram & trigram, then use word2vec to transform these words into vector. The word vector is built based on this \"universe\" of chinese words \n",
    "\n",
    "2) Given other news article on HK01, if the word has been seen in the previous text, a word vector will be calculated based on the word-cocurence matrix. Average word vector is being used to turn a paragraph into vectors.\n",
    "\n",
    "3) This is a classification problem, so i decided to use random forest. Random forest is a model based on multiple decision tree, randomly selected partial features & each tree vote for the final outcome. The random forest learn the relationship between the tag & the word matrix, and therefore able to predict the probable text based on the word feature. Please note that \"out of bag\" words is not taken care in this case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DW9oX2ebzc32"
   },
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3QQRAs3kbjKA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from nltk.util import ngrams\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import gensim\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8lzDircx8U3"
   },
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zH1vV8cxbp9K"
   },
   "outputs": [],
   "source": [
    "# Get bigram & tri-gram\n",
    "def get_token(contents):\n",
    "    phrases = []\n",
    "    for content in contents:\n",
    "        phrases.extend([''.join(i) for i in ngrams([i for i in content],2)])\n",
    "    for content in contents:\n",
    "        phrases.extend([''.join(i) for i in ngrams([i for i in content],3)])\n",
    "    return phrases\n",
    "\n",
    "\n",
    "#Flatten a nested list\n",
    "def flatten(l):\n",
    "    return [a for b in l for a in b]\n",
    "  \n",
    "def get_vector(x):\n",
    "    try:\n",
    "        return model.wv[x]\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "#Split text based on a list of seperators\n",
    "def split(txt, seps):\n",
    "    default_sep = seps[0]\n",
    "    for sep in seps[1:]:\n",
    "        txt = txt.replace(sep, default_sep)\n",
    "    return [i.strip() for i in txt.split(default_sep)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkxifJJXzaUP"
   },
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4Fz97XPGbtye"
   },
   "outputs": [],
   "source": [
    "#Get the data\n",
    "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRybGDvxCZ2dK7UPdKHUv8BG3QkNedvDrDOkrYf664i1uA_mpKh7L3BexFLwMkWytapJCXeQW2gJD7q/pub?gid=2044258515&single=true&output=csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# define the lookup for the label, and also the seperators for chinese text\n",
    "lookup = {'足球':1,'梁振英':2,'美國大選':3}\n",
    "sep = ('、','，','。','「','」','︰','||','】','【','：')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jfqkHorX0FMI"
   },
   "source": [
    "#### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "VtUy4PfrcDZ1",
    "outputId": "20bbb5aa-7f8c-4f79-ed50-ecd9b0fa4ead"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# clean the label\n",
    "df['tags'] = df.tags.map(lookup)\n",
    "\n",
    "# parse the text by beautifulsoup\n",
    "df['text']  = df.text.apply(lambda x: bs(x))\n",
    "df['text'] = df.text.apply(lambda x: x.text)\n",
    "\n",
    "#clean the data by seperators\n",
    "df['text'] = df.text.apply(lambda x:'||'.join(x.split()))\n",
    "df['text'] = df.text.apply(lambda x: split(x, sep))\n",
    "\n",
    "#Create text token, get the n-gram (bigram & trigram) of the text\n",
    "df['token'] = df.text.apply(lambda x: get_token(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7wb_J6kzmcQ"
   },
   "source": [
    "#### Train word2vec model using gensim and the word token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NE8w34ECmomR"
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(list(df.token), min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qW-25ZkfzsSc"
   },
   "source": [
    "#### Get the average word vector of a paragraphs for every token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aivpPLzmpa1a"
   },
   "outputs": [],
   "source": [
    "df['vector'] = df.token.apply(lambda x: np.mean(np.array([model.wv[i] for i in x]), axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QdUu-qfG0Niu"
   },
   "source": [
    "#### Look at the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "2z_-ckQ4pmv6",
    "outputId": "b2f59004-2a48-4f92-83e7-3f52f41aa73d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3443</td>\n",
       "      <td>足球</td>\n",
       "      <td>[利物浦重賽擊敗乙組仔, 英足盃過關, 英格蘭足總盃第三圈今晨重賽, 貴為英超勁旅的利物浦上...</td>\n",
       "      <td>[利物, 物浦, 浦重, 重賽, 賽擊, 擊敗, 敗乙, 乙組, 組仔, 英足, 足盃, 盃...</td>\n",
       "      <td>[0.9069747, -0.039209668, -0.4738193, -0.74298...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76056</td>\n",
       "      <td>足球</td>\n",
       "      <td>[, 中超, 恒大, 暴力戰, 絕殺國安, 楊智反重力插水惹爭議（有片）, 中超首輪賽事重頭...</td>\n",
       "      <td>[中超, 恒大, 暴力, 力戰, 絕殺, 殺國, 國安, 楊智, 智反, 反重, 重力, 力...</td>\n",
       "      <td>[0.60577834, -0.075798534, -0.3843291, -0.5955...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93405</td>\n",
       "      <td>足球</td>\n",
       "      <td>[, 歐霸決賽, 阿積士控球率起腳佔優, 隊長卡拉臣輸波不服氣, 阿積士以歐洲主要決賽最年輕...</td>\n",
       "      <td>[歐霸, 霸決, 決賽, 阿積, 積士, 士控, 控球, 球率, 率起, 起腳, 腳佔, 佔...</td>\n",
       "      <td>[0.7996664, -0.08279441, -0.51416713, -0.68100...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id tags                                               text  \\\n",
       "0   3443   足球  [利物浦重賽擊敗乙組仔, 英足盃過關, 英格蘭足總盃第三圈今晨重賽, 貴為英超勁旅的利物浦上...   \n",
       "1  76056   足球  [, 中超, 恒大, 暴力戰, 絕殺國安, 楊智反重力插水惹爭議（有片）, 中超首輪賽事重頭...   \n",
       "2  93405   足球  [, 歐霸決賽, 阿積士控球率起腳佔優, 隊長卡拉臣輸波不服氣, 阿積士以歐洲主要決賽最年輕...   \n",
       "\n",
       "                                               token  \\\n",
       "0  [利物, 物浦, 浦重, 重賽, 賽擊, 擊敗, 敗乙, 乙組, 組仔, 英足, 足盃, 盃...   \n",
       "1  [中超, 恒大, 暴力, 力戰, 絕殺, 殺國, 國安, 楊智, 智反, 反重, 重力, 力...   \n",
       "2  [歐霸, 霸決, 決賽, 阿積, 積士, 士控, 控球, 球率, 率起, 起腳, 腳佔, 佔...   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.9069747, -0.039209668, -0.4738193, -0.74298...  \n",
       "1  [0.60577834, -0.075798534, -0.3843291, -0.5955...  \n",
       "2  [0.7996664, -0.08279441, -0.51416713, -0.68100...  "
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the word vector into a dataframe of word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BVPIqN-WqvH3"
   },
   "outputs": [],
   "source": [
    "word_vector = pd.DataFrame(list(df.vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "dkLUEnrw1K1U",
    "outputId": "1868eb36-bac3-444e-8818-5ce5dfbb377d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99488491, 0.99232737, 0.99230769, 0.99228792, 0.99485861,\n",
       "       0.98457584, 0.98457584, 0.98457584, 0.99742931, 0.99484536])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rf, word_vector, df[['tags']], cv=10)\n",
    "scores                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "DMl5q2RnWrV3",
    "outputId": "a848bcc6-4b9d-4150-bc41-51e0f4e7d935"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(word_vector, df[['tags']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1p8x17QA1kRv"
   },
   "source": [
    "## Get test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "63sSDNQFsfvN"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vRybGDvxCZ2dK7UPdKHUv8BG3QkNedvDrDOkrYf664i1uA_mpKh7L3BexFLwMkWytapJCXeQW2gJD7q/pub?gid=1219023622&single=true&output=csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "QbNt5neQTd9A",
    "outputId": "829ce3ff-34f9-4533-811e-83a2fb50ef29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_test['text']  = df_test.text.apply(lambda x: bs(x))\n",
    "df_test['text'] = df_test.text.apply(lambda x: x.text)\n",
    "df_test['text'] = df_test.text.apply(lambda x:'||'.join(x.split()))\n",
    "df_test['text'] = df_test.text.apply(lambda x: split(x, sep))\n",
    "df_test['token'] = df_test.text.apply(lambda x: get_token(x))\n",
    "df_test['vector']  =df_test.token.apply(lambda x: np.mean(np.array([get_vector(i) for i in x if get_vector(i)!='']), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zBCK5u_ATnNn"
   },
   "outputs": [],
   "source": [
    "df_test['prediction'] = rf.predict(pd.DataFrame(list(df_test.vector)))\n",
    "df_test['prediction'] =  df_test.prediction.map({1:'足球',2:'梁振英',3:'美國大選'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9QrYBNeX3gr"
   },
   "source": [
    "#### Randomly check the model performance by eyeball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "colab_type": "code",
    "id": "XNE4TTyoYCo9",
    "outputId": "c092152a-927d-4f01-b43e-38f172fa6aa7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>token</th>\n",
       "      <th>vector</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>71755</td>\n",
       "      <td>[, 亞冠盃, 東方主場套票售罄, 對恒大單場門票僅餘特惠票, 2017年亞冠盃小組賽第一輪...</td>\n",
       "      <td>[亞冠, 冠盃, 東方, 方主, 主場, 場套, 套票, 票售, 售罄, 對恒, 恒大, 大...</td>\n",
       "      <td>[0.721277, -0.0036470664, -0.48476762, -0.7835...</td>\n",
       "      <td>足球</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>34879</td>\n",
       "      <td>[, 港超, 足總批准富力參賽, 放寬本地球員限制, 上陣名額4變3, 早前足總放風, 要求...</td>\n",
       "      <td>[港超, 足總, 總批, 批准, 准富, 富力, 力參, 參賽, 放寬, 寬本, 本地, 地...</td>\n",
       "      <td>[0.78223294, -0.09413832, -0.60155964, -0.8187...</td>\n",
       "      <td>足球</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>90787</td>\n",
       "      <td>[, 金球, 瑞士盃賽現, 驚世金球, , 窄角度倒掛解圍擺烏龍（有片）, 烏龍球往往是金球...</td>\n",
       "      <td>[金球, 瑞士, 士盃, 盃賽, 賽現, 驚世, 世金, 金球, 窄角, 角度, 度倒, 倒...</td>\n",
       "      <td>[0.4636246, 0.10082367, -0.2101591, -0.5601781...</td>\n",
       "      <td>足球</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>66947</td>\n",
       "      <td>[, 特朗普就任, 慶典獻舞, , 火箭女郎, 不情願, 他不是我的總統, 珀爾自小熱愛跳舞...</td>\n",
       "      <td>[特朗, 朗普, 普就, 就任, 慶典, 典獻, 獻舞, 火箭, 箭女, 女郎, 不情, 情...</td>\n",
       "      <td>[0.5901156, -0.2431006, -0.4420096, -0.6486404...</td>\n",
       "      <td>美國大選</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>53047</td>\n",
       "      <td>[, 西甲, C朗續約皇家馬德里至2021年, , 我還可多踢10年, , C朗和母親及其經...</td>\n",
       "      <td>[西甲, C朗, 朗續, 續約, 約皇, 皇家, 家馬, 馬德, 德里, 里至, 至2, 2...</td>\n",
       "      <td>[0.9795927, -0.17059559, -0.6822006, -0.998758...</td>\n",
       "      <td>足球</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>13705</td>\n",
       "      <td>[, 美國大選, 特朗普場外大戰克魯茲, 互嘲對方太座愈來愈卑鄙, , 警告你別搞我妻子, ...</td>\n",
       "      <td>[美國, 國大, 大選, 特朗, 朗普, 普場, 場外, 外大, 大戰, 戰克, 克魯, 魯...</td>\n",
       "      <td>[0.57302237, -0.4207809, -0.3553377, -0.600226...</td>\n",
       "      <td>美國大選</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>46314</td>\n",
       "      <td>[, 英超, 曼聯憾和史篤城, 普巴漸上力, 朗尼甩腳造就入球, 走出谷底, 挾3連勝之姿的...</td>\n",
       "      <td>[英超, 曼聯, 聯憾, 憾和, 和史, 史篤, 篤城, 普巴, 巴漸, 漸上, 上力, 朗...</td>\n",
       "      <td>[0.92521346, -0.13470419, -0.5673328, -0.85081...</td>\n",
       "      <td>足球</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>45919</td>\n",
       "      <td>[, 蔡東豪專欄, 如果梁振英是CEO不是特首, 曾俊華捱到幾耐？, 美國總統候選人特朗普認...</td>\n",
       "      <td>[蔡東, 東豪, 豪專, 專欄, 如果, 果梁, 梁振, 振英, 英是, 是C, CE, E...</td>\n",
       "      <td>[0.69771504, -0.31719276, -0.51172084, -0.5740...</td>\n",
       "      <td>梁振英</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>26302</td>\n",
       "      <td>[, 歐國盃, 神射手華迪貶後備, 英格蘭鬥威爾斯要出鞘, B組, 英格蘭, Vs, 威爾斯...</td>\n",
       "      <td>[歐國, 國盃, 神射, 射手, 手華, 華迪, 迪貶, 貶後, 後備, 英格, 格蘭, 蘭...</td>\n",
       "      <td>[0.85919666, -0.106865436, -0.49711698, -0.742...</td>\n",
       "      <td>足球</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>23860</td>\n",
       "      <td>[假梁振英fb宣布選特首, 大量網民, 中伏, , 真正梁振英fb帳戶名稱為, CY, Le...</td>\n",
       "      <td>[假梁, 梁振, 振英, 英f, fb, b宣, 宣布, 布選, 選特, 特首, 大量, 量...</td>\n",
       "      <td>[0.76285106, 0.016055072, -0.30766246, -0.6783...</td>\n",
       "      <td>梁振英</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  \\\n",
       "819  71755  [, 亞冠盃, 東方主場套票售罄, 對恒大單場門票僅餘特惠票, 2017年亞冠盃小組賽第一輪...   \n",
       "406  34879  [, 港超, 足總批准富力參賽, 放寬本地球員限制, 上陣名額4變3, 早前足總放風, 要求...   \n",
       "937  90787  [, 金球, 瑞士盃賽現, 驚世金球, , 窄角度倒掛解圍擺烏龍（有片）, 烏龍球往往是金球...   \n",
       "785  66947  [, 特朗普就任, 慶典獻舞, , 火箭女郎, 不情願, 他不是我的總統, 珀爾自小熱愛跳舞...   \n",
       "620  53047  [, 西甲, C朗續約皇家馬德里至2021年, , 我還可多踢10年, , C朗和母親及其經...   \n",
       "157  13705  [, 美國大選, 特朗普場外大戰克魯茲, 互嘲對方太座愈來愈卑鄙, , 警告你別搞我妻子, ...   \n",
       "489  46314  [, 英超, 曼聯憾和史篤城, 普巴漸上力, 朗尼甩腳造就入球, 走出谷底, 挾3連勝之姿的...   \n",
       "481  45919  [, 蔡東豪專欄, 如果梁振英是CEO不是特首, 曾俊華捱到幾耐？, 美國總統候選人特朗普認...   \n",
       "324  26302  [, 歐國盃, 神射手華迪貶後備, 英格蘭鬥威爾斯要出鞘, B組, 英格蘭, Vs, 威爾斯...   \n",
       "286  23860  [假梁振英fb宣布選特首, 大量網民, 中伏, , 真正梁振英fb帳戶名稱為, CY, Le...   \n",
       "\n",
       "                                                 token  \\\n",
       "819  [亞冠, 冠盃, 東方, 方主, 主場, 場套, 套票, 票售, 售罄, 對恒, 恒大, 大...   \n",
       "406  [港超, 足總, 總批, 批准, 准富, 富力, 力參, 參賽, 放寬, 寬本, 本地, 地...   \n",
       "937  [金球, 瑞士, 士盃, 盃賽, 賽現, 驚世, 世金, 金球, 窄角, 角度, 度倒, 倒...   \n",
       "785  [特朗, 朗普, 普就, 就任, 慶典, 典獻, 獻舞, 火箭, 箭女, 女郎, 不情, 情...   \n",
       "620  [西甲, C朗, 朗續, 續約, 約皇, 皇家, 家馬, 馬德, 德里, 里至, 至2, 2...   \n",
       "157  [美國, 國大, 大選, 特朗, 朗普, 普場, 場外, 外大, 大戰, 戰克, 克魯, 魯...   \n",
       "489  [英超, 曼聯, 聯憾, 憾和, 和史, 史篤, 篤城, 普巴, 巴漸, 漸上, 上力, 朗...   \n",
       "481  [蔡東, 東豪, 豪專, 專欄, 如果, 果梁, 梁振, 振英, 英是, 是C, CE, E...   \n",
       "324  [歐國, 國盃, 神射, 射手, 手華, 華迪, 迪貶, 貶後, 後備, 英格, 格蘭, 蘭...   \n",
       "286  [假梁, 梁振, 振英, 英f, fb, b宣, 宣布, 布選, 選特, 特首, 大量, 量...   \n",
       "\n",
       "                                                vector prediction  \n",
       "819  [0.721277, -0.0036470664, -0.48476762, -0.7835...         足球  \n",
       "406  [0.78223294, -0.09413832, -0.60155964, -0.8187...         足球  \n",
       "937  [0.4636246, 0.10082367, -0.2101591, -0.5601781...         足球  \n",
       "785  [0.5901156, -0.2431006, -0.4420096, -0.6486404...       美國大選  \n",
       "620  [0.9795927, -0.17059559, -0.6822006, -0.998758...         足球  \n",
       "157  [0.57302237, -0.4207809, -0.3553377, -0.600226...       美國大選  \n",
       "489  [0.92521346, -0.13470419, -0.5673328, -0.85081...         足球  \n",
       "481  [0.69771504, -0.31719276, -0.51172084, -0.5740...        梁振英  \n",
       "324  [0.85919666, -0.106865436, -0.49711698, -0.742...         足球  \n",
       "286  [0.76285106, 0.016055072, -0.30766246, -0.6783...        梁振英  "
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Hyperparameter tuning\n",
    "to search for the optimal parameter, we can use a gridsearch to search for the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "parameters = {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "clf = GridSearchCV(rf, parameters, cv=5)\n",
    "\n",
    "scores = cross_val_score(clf, word_vector, df[['tags']], cv=10)\n",
    "scores   "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Q3a.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
